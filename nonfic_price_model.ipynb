{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UK Non-Fiction Book Sales Analysis, 2014-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataset consists of the top 5000 non-fiction titles (HB and PB) sold through UK TCM between 2014-2023.\n",
    "* Additional data points for each title were added from Goodreads (GR) and Google Books (GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/final_books_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # 50,000 rows, 23 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns containing non-numeric or non-pertinent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Sales_Year\", \"Publisher Group\", \"RRP\", \"ASP\", \"Binding\", \"Publ Date\", \"Product Class\", \"GR_Pages\", \"GB_Pages\"]]\n",
    "df.head() # 50,000 rows, 8 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, completing and converting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display nulls per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Binding\"].value_counts() # 33,370 PBs, 16,630 HBs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Integer encode hardbacks as 0, paperbacks as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"Binding\"] == \"Hardback\"), \"Binding\"] = 0\n",
    "df.loc[(df[\"Binding\"] == \"Paperback\"), \"Binding\"] = 1\n",
    "df[\"Binding\"] = df[\"Binding\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RRP\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill 879 missing RRPs with values calculated from average sale price (ASP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column showing average discount on RRP for each title\n",
    "df[\"ASP_Discount\"] = 1 - ((df[\"RRP\"].dropna() - df[\"ASP\"]) / df[\"RRP\"].dropna())\n",
    "\n",
    "# Calculate average level of discount for hardbacks and paperbacks\n",
    "result = df.groupby(\"Binding\", as_index=False)[\"ASP_Discount\"].mean()\n",
    "mean_hb_disc = result[\"ASP_Discount\"].iloc[0]\n",
    "mean_pb_disc = result[\"ASP_Discount\"].iloc[1]\n",
    "\n",
    "print(mean_hb_disc) # ~0.7 of RRP\n",
    "print(mean_pb_disc) # ~0.75 of RRP\n",
    "\n",
    "# Fill missing RRPs based on title's ASP and format, using mean discount calculation\n",
    "df.loc[(df[\"RRP\"].isnull()) & (df[\"Binding\"] == \"Hardback\"), \"RRP\"] = (\n",
    "    1 / mean_hb_disc\n",
    ") * df[\"ASP\"]\n",
    "df.loc[(df[\"RRP\"].isnull()) & (df[\"Binding\"] == \"Paperback\"), \"RRP\"] = (\n",
    "    1 / mean_pb_disc\n",
    ") * df[\"ASP\"]\n",
    "\n",
    "# Fill missing ASP Discounts with average values per format\n",
    "df.loc[(df[\"ASP_Discount\"].isnull()) & (df[\"Binding\"] == \"Hardback\"), \"ASP_Discount\"] = mean_hb_disc\n",
    "df.loc[(df[\"ASP_Discount\"].isnull()) & (df[\"Binding\"] == \"Paperback\"), \"ASP_Discount\"] = mean_pb_disc\n",
    "\n",
    "# Drop ASP and ASP_Discount columns\n",
    "df = df.drop(columns=[\"ASP\", \"ASP_Discount\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate top 25 most frequently occurring RRPs for both hardbacks and paperbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbs = df[df[\"Binding\"] == 0]\n",
    "pbs = df[df[\"Binding\"] == 1]\n",
    "print(hbs[\"RRP\"].nunique()) # 143 unique hardback RRPs\n",
    "print(pbs[\"RRP\"].nunique()) # 204 unique hardback RRPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_top_25 = hbs[\"RRP\"].value_counts().nlargest(25)\n",
    "hb_rrps = hb_top_25.index.tolist()\n",
    "hb_rrps.sort()\n",
    "print(hb_top_25.sum()) # Top 25 hardback RRPs account for 15,304 out of 16,630 titles\n",
    "print(hb_rrps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_top_25 = pbs[\"RRP\"].value_counts().nlargest(25)\n",
    "pb_rrps = pb_top_25.index.tolist()\n",
    "pb_rrps.sort()\n",
    "print(pb_top_25.sum()) # Top 25 hardback RRPs account for 30,860 out of 33,370 titles\n",
    "print(pb_rrps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using top 25 lists, round non-standard RRPs to the nearest standard value if within Â£0.49 difference - else drop as outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RRP_Rounded column, rounding prices to the nearest value in top 25 lists. Extract any significant outliers\n",
    "df[\"RRP_Rounded\"] = 0.0\n",
    "outlier_rrps = []\n",
    "\n",
    "def find_closest(value, reference_list):\n",
    "    closest = min(reference_list, key=lambda x: abs(x - value))\n",
    "    return closest\n",
    "\n",
    "def round_rrps(format, top_20_rrps):\n",
    "    for index, value in format[\"RRP\"].items():\n",
    "        if value in top_20_rrps:\n",
    "            df.at[index, \"RRP_Rounded\"] = value\n",
    "        else:\n",
    "            closest = find_closest(value, top_20_rrps)\n",
    "            if abs(closest - value) <= 0.49:\n",
    "                df.at[index, \"RRP_Rounded\"] = closest\n",
    "            else:\n",
    "                outlier_rrps.append(value)\n",
    "                df.at[index, \"RRP_Rounded\"] = 0.0\n",
    "\n",
    "round_rrps(hbs, hb_rrps)\n",
    "round_rrps(pbs, pb_rrps)\n",
    "\n",
    "print(len(outlier_rrps)) # 2,442 RRPs fall outside the top 25 HB and PB RRPs - drop accordingly\n",
    "print(pd.Series(outlier_rrps).nunique()) # 130 unique, non-standard RRPs to be dropped\n",
    "print(df[\"RRP_Rounded\"].nunique()) #35 unique, standard RRPs remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show RRP boxplots inc outliers before rounding\n",
    "sns.set_theme(rc={\"figure.figsize\": (6, 5)})\n",
    "ax = sns.boxplot(x=\"Binding\", y=\"RRP\", data=df)\n",
    "ax.set_title(\"Distribution of RRPs inc outliers (no rounding)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with non-standard RRPs\n",
    "df = df[df[\"RRP_Rounded\"] > 0]\n",
    "\n",
    "# Show boxplots w/o outliers\n",
    "ax = sns.boxplot(x=\"Binding\", y=\"RRP_Rounded\", data=df, showfliers=False)\n",
    "ax.set_title(\"Distribution of RRPs after rounding applied\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original RRP column\n",
    "df = df.drop(columns=[\"RRP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe page count data from Goodreads\n",
    "df[\"GR_Pages\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find and drop outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=df[\"GR_Pages\"]) \n",
    "ax.set_title(\"Distribution of page counts from Goodreads\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe page count data from Google Books\n",
    "df[\"GB_Pages\"].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80,000pp outlier clearly an error - drop corresponding row\n",
    "df = df[df[\"GB_Pages\"] < 10000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=df[\"GB_Pages\"])\n",
    "ax.set_title(\"Distribution of page counts from Google Books\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fill 3,155 nulls in GR page counts with GB data, or mean where data not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill GR_Pages nulls with value from GB_Pages\n",
    "df[\"Pages\"] = df.apply(\n",
    "    lambda row: (\n",
    "        row[\"GB_Pages\"]\n",
    "        if pd.isnull(row[\"GR_Pages\"]) and pd.notnull(row[\"GB_Pages\"])\n",
    "        else row[\"GR_Pages\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Fill remainder with mean page count per format, rounded to nearest multiple of 16\n",
    "mean_hb_pages = 16 * round(df.loc[df[\"Binding\"] == 0][\"Pages\"].mean() / 16)\n",
    "mean_pb_pages = 16 * round(df.loc[df[\"Binding\"] == 1][\"Pages\"].mean() / 16)\n",
    "print(mean_hb_pages) # 272pp \n",
    "print(mean_pb_pages) # 288pp\n",
    "df.loc[df[\"Binding\"] == 0][\"Pages\"].fillna(mean_hb_pages)\n",
    "df.loc[df[\"Binding\"] == 1][\"Pages\"].fillna(mean_pb_pages)\n",
    "\n",
    "# Convert Pages column from float to int\n",
    "df[\"Pages\"] = df[\"Pages\"].astype(int)\n",
    "\n",
    "# Drop now redundant GR_Pages and GB_Pages columns\n",
    "df = df.drop(columns=[\"GR_Pages\", \"GB_Pages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Group titles by publishing house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define publishing houses and their respective divisions\n",
    "publishers = {\n",
    "    \"PRH\": [\n",
    "        \"Dorling Kindersley Grp\",\n",
    "        \"Penguin Grp\",\n",
    "        \"Random House Grp\",\n",
    "        \"Transworld Grp\",\n",
    "    ],\n",
    "    \"Hachette\": [\n",
    "        \"Hachette Books Ireland Grp\",\n",
    "        \"Hachette Children's Grp\",\n",
    "        \"Headline Grp\",\n",
    "        \"Hodder & Stoughton Grp\",\n",
    "        \"John Murray Press Group\",\n",
    "        \"Little, Brown Book Grp\",\n",
    "        \"Octopus Publishing Grp\",\n",
    "        \"Orion Grp\",\n",
    "        \"Perseus Books Group\",\n",
    "        \"Quercus Grp\",\n",
    "    ],\n",
    "    \"Pan_Mac\": [\n",
    "        \"Pan Macmillan Grp\",\n",
    "    ],\n",
    "    \"HC\": [\n",
    "        \"HarperCollins Grp\",\n",
    "    ],\n",
    "    \"SS\": [\n",
    "        \"Simon & Schuster Grp\",\n",
    "    ],\n",
    "    \"Bonnier\": [\n",
    "        \"Bonnier Books UK Publishing Gr\",\n",
    "    ],\n",
    "    \"Bloomsbury\": [\n",
    "        \"Bloomsbury Grp\",\n",
    "    ],\n",
    "    \"IA\": [\n",
    "        \"Faber Grp\",\n",
    "        \"Atlantic Books Grp\",\n",
    "        \"Canongate Grp\",\n",
    "        \"Duckworth Books Group\",\n",
    "        \"Europa Editions Grp\",\n",
    "        \"Fitzcarraldo Editions Grp\",\n",
    "        \"Granta Grp\",\n",
    "        \"Lonely Planet Grp\",\n",
    "        \"Murdoch Books Grp\",\n",
    "        \"Oneworld Publications Grp\",\n",
    "        \"Profile Books Group\",\n",
    "        \"Pushkin Grp\",\n",
    "        \"Scribe Publications Group\",\n",
    "        \"Swift Press\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "def get_publisher(publisher_group):\n",
    "    for publisher, divisions in publishers.items():\n",
    "        if publisher_group in divisions:\n",
    "            return publisher\n",
    "    return \"Other\"\n",
    "\n",
    "# Assign divisions to publishers (or \"Other\" if not a member of a major group)\n",
    "df[\"Publisher\"] = df[\"Publisher Group\"].apply(get_publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Publisher\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. One-hot encode Publishers and drop original Publisher Group column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode publishers\n",
    "df = pd.get_dummies(df, columns=[\"Publisher\"], prefix=\"\", prefix_sep=\"\", dtype=int)\n",
    "# Drop original Publisher Group columns\n",
    "df = df.drop(columns=[\"Publisher Group\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract year and month from Publ Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime format before extracting dates\n",
    "df[\"Publ Date\"] = pd.to_datetime(df[\"Publ Date\"], format=\"%d/%m/%Y\")\n",
    "df[\"Pub_Year\"] = df[\"Publ Date\"].dt.year\n",
    "df[\"Pub_Month\"] = df[\"Publ Date\"].dt.month\n",
    "\n",
    "# Drop original column\n",
    "df = df.drop(columns=[\"Publ Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres and Subgenres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Export and integer encode genres / subgenres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define top-level genres\n",
    "genre_dict = {\n",
    "    1: \"The Arts\",\n",
    "    2: \"Encyclopedias and Reference Works\",\n",
    "    3: \"Literature and Literary Studies\",\n",
    "    4: \"Biography and Autobiography\",\n",
    "    5: \"History and Archaeology\",\n",
    "    6: \"Religion and Belief Systems\",\n",
    "    7: \"Politics and Government\",\n",
    "    8: \"Popular Science, Popular Culture and Natural History\",\n",
    "    9: \"Health and Relationships\",\n",
    "    10: \"Mind, Body, Spirit\",\n",
    "    11: \"Lifestyle, Hobbies and Leisure\",\n",
    "    12: \"Transport\",\n",
    "    13: \"Humour, Trivia and Puzzles\",\n",
    "    14: \"Travel and Holiday\",\n",
    "    15: \"Sports and Active Pursuits\",\n",
    "    16: \"Cookery, Food and Drink\",\n",
    "    17: \"Personal Development and Practical Advice\",\n",
    "    18: \"True Crime and True Stories\",\n",
    "}\n",
    "qualifiers_dict = {\"\": \"0\", \"A\": \"1\", \"T\": \"2\"}\n",
    "\n",
    "# Create new genre DF by exporting unique values from \"Product Class\" column\n",
    "genre_df = pd.DataFrame(df[\"Product Class\"].unique(), columns=[\"Full_String\"])\n",
    "\n",
    "# Split the \"T0.0\"-formatted codes into Genre/Subgenre codes, qualifiers and descriptions\n",
    "pattern = (\n",
    "    r\"T(?P<Genre_Code>\\d{1,2})\\.(?P<Sub_Code>\\d{1})(?P<Qualifier>\\w?)\\s(?P<Sub_Desc>.+)\"\n",
    ")\n",
    "expanded_df = genre_df[\"Full_String\"].str.extract(pattern)\n",
    "genre_df = pd.concat([genre_df, expanded_df], axis=1)\n",
    "genre_df[[\"Genre_Code\", \"Sub_Code\"]] = genre_df[[\"Genre_Code\", \"Sub_Code\"]].astype(int)\n",
    "\n",
    "# Convert qualifiers to numeric values from qualifiers_dict\n",
    "genre_df[\"Qualifier\"] = genre_df[\"Qualifier\"].replace(qualifiers_dict)\n",
    "genre_df[\"Qualifier\"] = genre_df[\"Qualifier\"].astype(int)\n",
    "\n",
    "# Add Genre_Desc column using values from genre_dict, tidy up order and export to CSV\n",
    "genre_df[\"Genre_Desc\"] = genre_df[\"Genre_Code\"].astype(int).map(genre_dict)\n",
    "genre_df = genre_df.iloc[:, [0, 1, 2, 3, 5, 4]]\n",
    "genre_df = genre_df.sort_values(by=[\"Genre_Code\", \"Sub_Code\"]).reset_index(drop=True)\n",
    "genre_df.to_csv(\"./data/genres.csv\", index=False)\n",
    "\n",
    "# # Add newly defined genre codes and drop \"Product Class\" and \"Full_String\" columns\n",
    "df = df.merge(\n",
    "    genre_df[[\"Full_String\", \"Genre_Code\", \"Sub_Code\", \"Qualifier\"]],\n",
    "    left_on=\"Product Class\",\n",
    "    right_on=\"Full_String\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df = df.drop(columns=[\"Product Class\", \"Full_String\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Display YoY variation in mean RRP by binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary DF grouped by Sales_Year and Binding for ease of further analysis\n",
    "temp_df = df.groupby([\"Sales_Year\", \"Binding\"])[\"RRP_Rounded\"].mean().unstack(level=1)\n",
    "\n",
    "# Reshape temporary DF for plotting\n",
    "plot_df = temp_df.reset_index().melt(\n",
    "    id_vars=\"Sales_Year\", var_name=\"Binding\", value_name=\"RRP_Rounded\"\n",
    ")\n",
    "years = plot_df[\"Sales_Year\"].unique()\n",
    "\n",
    "# Create the plot\n",
    "ax = sns.lmplot(\n",
    "    data=plot_df,\n",
    "    x=\"Sales_Year\",\n",
    "    y=\"RRP_Rounded\",\n",
    "    hue=\"Binding\",\n",
    "    palette=\"bright\",\n",
    "    facet_kws=dict(legend_out=False),\n",
    ")\n",
    "ax.set(title=\"YoY variation in mean RRP by binding\", xlabel=\"Sales_Year\", ylabel=\"RRP_Rounded\")\n",
    "plt.tight_layout()\n",
    "plt.show() # Clear upward trend in RRP from 2014 to 2023, so keep Sales_Year as pertinent data point for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # 42080 rows remaining of the original 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and optimising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim of model: accurately predict HB and PB RRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, PredictionErrorDisplay\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up train-test split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y values\n",
    "X = df.drop(columns=[\"RRP_Rounded\"])\n",
    "y = df[\"RRP_Rounded\"]\n",
    "\n",
    "# Set up train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# Standardise features with both StandardScaler and MinMaxScaler\n",
    "ss = StandardScaler()\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)\n",
    "mm = MinMaxScaler()\n",
    "X_train_mm = mm.fit_transform(X_train)\n",
    "X_test_mm = mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with scaled data - first StandardScaler\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_ss, y_train)\n",
    "y_pred_ss = model.predict(X_test_ss)\n",
    "mse_ss = mean_squared_error(y_test, y_pred_ss)\n",
    "print(mse_ss)\n",
    "\n",
    "# Then MinMaxScaler\n",
    "model.fit(X_train_mm, y_train)\n",
    "y_pred_mm = model.predict(X_test_mm)\n",
    "mse_mm = mean_squared_error(y_test, y_pred_mm)\n",
    "print(mse_mm) # No tangible difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different values for decision tree max_depth\n",
    "values = [i for i in range(1, 21)]\n",
    "test_scores = []\n",
    "for i in values:\n",
    "    model = DecisionTreeRegressor(max_depth=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_scores.append(mse)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model = xgboost.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse) # Good starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different values for n_estimators\n",
    "values = [i for i in range(100, 201, 10)]\n",
    "test_scores = []\n",
    "for i in values:\n",
    "    model = RandomForestRegressor(n_estimators=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_scores.append(mse)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500, 1000],\n",
    "    \"max_depth\": [10, 20, 50, 100, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\", 0.2, 0.5, 0.8],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                                   n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestRegressor()\n",
    "# scores = cross_val_score(model, X, y, cv=10)\n",
    "# print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "# PredictionErrorDisplay.from_predictions(\n",
    "#     y,\n",
    "#     y_pred=y_pred,\n",
    "#     kind=\"actual_vs_predicted\",\n",
    "#     subsample=100,\n",
    "#     ax=axs[0],\n",
    "#     random_state=0,\n",
    "# )\n",
    "# axs[0].set_title(\"Actual vs. Predicted values\")\n",
    "# PredictionErrorDisplay.from_predictions(\n",
    "#     y_train,\n",
    "#     y_pred=y_pred,\n",
    "#     kind=\"residual_vs_predicted\",\n",
    "#     subsample=100,\n",
    "#     ax=axs[1],\n",
    "#     random_state=0,\n",
    "# )\n",
    "# axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
    "# fig.suptitle(\"Plotting cross-validated predictions\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
